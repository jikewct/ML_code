{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jikewct/anaconda3/envs/py3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "os.chdir('/home/jikewct/public/jikewct/Repos/ml_code')\n",
    "from  network import ncsnpp, lora_ncsnpp\n",
    "\n",
    "from models import FlowMatching\n",
    "from models import *\n",
    "from models import model_utils\n",
    "from network.layers.layer_utils import mark_only_lora_as_trainable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from configs.flow_matching.cifar10_ncsnpp import get_config\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score_sde_model(model_name, checkpoint, fm_model):\n",
    "    #model_name = \"2_rect_flow\"\n",
    "    model_path = \"/home/jikewct/public/jikewct/Model/rect_flow/\"\n",
    "    model_checkpoint = f\"{model_path}/{model_name}_{checkpoint}\"\n",
    "    loaded_state = torch.load(model_checkpoint)\n",
    "    save_dir = os.path.split(model_checkpoint)[0] \n",
    "    model = loaded_state['model']\n",
    "    cvt_model = dict()\n",
    "\n",
    "    for  key in  model.keys():\n",
    "        cvt_key = key.replace(\"module.\", \"\")\n",
    "        cvt_model[cvt_key] = model[key]\n",
    "    torch.save(cvt_model , model_path + f\"/{model_name}_cvt_model.pth\")\n",
    "    fm_model.network.load_state_dict(cvt_model)\n",
    "    model_params = fm_model.network.parameters()\n",
    "    shadow_params = loaded_state['ema']['shadow_params']\n",
    "    #print(len(model_params), len(shadow_params))\n",
    "    parameters = [p for p in model_params if p.requires_grad]\n",
    "    for ema_param , model_param in zip(shadow_params, parameters):\n",
    "        if model_param.requires_grad:\n",
    "            #print(f\"copy shape:{model_param.data.shape}\")\n",
    "            model_param.data.copy_(ema_param.data)\n",
    "    torch.save(fm_model.network.state_dict() ,model_path + f\"/{model_name}_model_ema.pth\")\n",
    "\n",
    "# from configs.flow_matching.cifar10_ncsnpp import get_config\n",
    "# config = get_config()\n",
    "# fm_model = model_utils.create_model(config)\n",
    "# convert_score_sde_model(\"2_rect_flow\", \"checkpoint_6.pth\", fm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_ncsnpp\n"
     ]
    }
   ],
   "source": [
    "from configs.flow_matching.afhq_lora_dog_ncsnpp import get_config\n",
    "config = get_config()\n",
    "print(config.model.nn_name)\n",
    "afhq_lora_dog_model = model_utils.create_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_state = torch.load(config.training.model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['sigmas', 'all_modules.0.W', 'all_modules.1.weight', 'all_modules.1.bias', 'all_modules.2.weight', 'all_modules.2.bias', 'all_modules.3.weight', 'all_modules.3.bias', 'all_modules.4.GroupNorm_0.weight', 'all_modules.4.GroupNorm_0.bias', 'all_modules.4.Conv_0.weight', 'all_modules.4.Conv_0.bias', 'all_modules.4.Dense_0.weight', 'all_modules.4.Dense_0.bias', 'all_modules.4.GroupNorm_1.weight', 'all_modules.4.GroupNorm_1.bias', 'all_modules.4.Conv_1.weight', 'all_modules.4.Conv_1.bias', 'all_modules.5.GroupNorm_0.weight', 'all_modules.5.GroupNorm_0.bias', 'all_modules.5.Conv_0.weight', 'all_modules.5.Conv_0.bias', 'all_modules.5.Dense_0.weight', 'all_modules.5.Dense_0.bias', 'all_modules.5.GroupNorm_1.weight', 'all_modules.5.GroupNorm_1.bias', 'all_modules.5.Conv_1.weight', 'all_modules.5.Conv_1.bias', 'all_modules.6.GroupNorm_0.weight', 'all_modules.6.GroupNorm_0.bias', 'all_modules.6.Conv_0.weight', 'all_modules.6.Conv_0.bias', 'all_modules.6.Dense_0.weight', 'all_modules.6.Dense_0.bias', 'all_modules.6.GroupNorm_1.weight', 'all_modules.6.GroupNorm_1.bias', 'all_modules.6.Conv_1.weight', 'all_modules.6.Conv_1.bias', 'all_modules.6.Conv_2.weight', 'all_modules.6.Conv_2.bias', 'all_modules.7.Conv_0.weight', 'all_modules.7.Conv_0.bias', 'all_modules.8.GroupNorm_0.weight', 'all_modules.8.GroupNorm_0.bias', 'all_modules.8.Conv_0.weight', 'all_modules.8.Conv_0.bias', 'all_modules.8.Dense_0.weight', 'all_modules.8.Dense_0.bias', 'all_modules.8.GroupNorm_1.weight', 'all_modules.8.GroupNorm_1.bias', 'all_modules.8.Conv_1.weight', 'all_modules.8.Conv_1.bias', 'all_modules.9.GroupNorm_0.weight', 'all_modules.9.GroupNorm_0.bias', 'all_modules.9.Conv_0.weight', 'all_modules.9.Conv_0.bias', 'all_modules.9.Dense_0.weight', 'all_modules.9.Dense_0.bias', 'all_modules.9.GroupNorm_1.weight', 'all_modules.9.GroupNorm_1.bias', 'all_modules.9.Conv_1.weight', 'all_modules.9.Conv_1.bias', 'all_modules.10.GroupNorm_0.weight', 'all_modules.10.GroupNorm_0.bias', 'all_modules.10.Conv_0.weight', 'all_modules.10.Conv_0.bias', 'all_modules.10.Dense_0.weight', 'all_modules.10.Dense_0.bias', 'all_modules.10.GroupNorm_1.weight', 'all_modules.10.GroupNorm_1.bias', 'all_modules.10.Conv_1.weight', 'all_modules.10.Conv_1.bias', 'all_modules.10.Conv_2.weight', 'all_modules.10.Conv_2.bias', 'all_modules.11.Conv_0.weight', 'all_modules.11.Conv_0.bias', 'all_modules.12.GroupNorm_0.weight', 'all_modules.12.GroupNorm_0.bias', 'all_modules.12.Conv_0.weight', 'all_modules.12.Conv_0.bias', 'all_modules.12.Dense_0.weight', 'all_modules.12.Dense_0.bias', 'all_modules.12.GroupNorm_1.weight', 'all_modules.12.GroupNorm_1.bias', 'all_modules.12.Conv_1.weight', 'all_modules.12.Conv_1.bias', 'all_modules.12.Conv_2.weight', 'all_modules.12.Conv_2.bias', 'all_modules.13.GroupNorm_0.weight', 'all_modules.13.GroupNorm_0.bias', 'all_modules.13.Conv_0.weight', 'all_modules.13.Conv_0.bias', 'all_modules.13.Dense_0.weight', 'all_modules.13.Dense_0.bias', 'all_modules.13.GroupNorm_1.weight', 'all_modules.13.GroupNorm_1.bias', 'all_modules.13.Conv_1.weight', 'all_modules.13.Conv_1.bias', 'all_modules.14.GroupNorm_0.weight', 'all_modules.14.GroupNorm_0.bias', 'all_modules.14.Conv_0.weight', 'all_modules.14.Conv_0.bias', 'all_modules.14.Dense_0.weight', 'all_modules.14.Dense_0.bias', 'all_modules.14.GroupNorm_1.weight', 'all_modules.14.GroupNorm_1.bias', 'all_modules.14.Conv_1.weight', 'all_modules.14.Conv_1.bias', 'all_modules.14.Conv_2.weight', 'all_modules.14.Conv_2.bias', 'all_modules.15.Conv_0.weight', 'all_modules.15.Conv_0.bias', 'all_modules.16.GroupNorm_0.weight', 'all_modules.16.GroupNorm_0.bias', 'all_modules.16.Conv_0.weight', 'all_modules.16.Conv_0.bias', 'all_modules.16.Dense_0.weight', 'all_modules.16.Dense_0.bias', 'all_modules.16.GroupNorm_1.weight', 'all_modules.16.GroupNorm_1.bias', 'all_modules.16.Conv_1.weight', 'all_modules.16.Conv_1.bias', 'all_modules.17.GroupNorm_0.weight', 'all_modules.17.GroupNorm_0.bias', 'all_modules.17.NIN_0.W', 'all_modules.17.NIN_0.b', 'all_modules.17.NIN_1.W', 'all_modules.17.NIN_1.b', 'all_modules.17.NIN_2.W', 'all_modules.17.NIN_2.b', 'all_modules.17.NIN_3.W', 'all_modules.17.NIN_3.b', 'all_modules.18.GroupNorm_0.weight', 'all_modules.18.GroupNorm_0.bias', 'all_modules.18.Conv_0.weight', 'all_modules.18.Conv_0.bias', 'all_modules.18.Dense_0.weight', 'all_modules.18.Dense_0.bias', 'all_modules.18.GroupNorm_1.weight', 'all_modules.18.GroupNorm_1.bias', 'all_modules.18.Conv_1.weight', 'all_modules.18.Conv_1.bias', 'all_modules.19.GroupNorm_0.weight', 'all_modules.19.GroupNorm_0.bias', 'all_modules.19.NIN_0.W', 'all_modules.19.NIN_0.b', 'all_modules.19.NIN_1.W', 'all_modules.19.NIN_1.b', 'all_modules.19.NIN_2.W', 'all_modules.19.NIN_2.b', 'all_modules.19.NIN_3.W', 'all_modules.19.NIN_3.b', 'all_modules.20.GroupNorm_0.weight', 'all_modules.20.GroupNorm_0.bias', 'all_modules.20.Conv_0.weight', 'all_modules.20.Conv_0.bias', 'all_modules.20.Dense_0.weight', 'all_modules.20.Dense_0.bias', 'all_modules.20.GroupNorm_1.weight', 'all_modules.20.GroupNorm_1.bias', 'all_modules.20.Conv_1.weight', 'all_modules.20.Conv_1.bias', 'all_modules.21.GroupNorm_0.weight', 'all_modules.21.GroupNorm_0.bias', 'all_modules.21.NIN_0.W', 'all_modules.21.NIN_0.b', 'all_modules.21.NIN_1.W', 'all_modules.21.NIN_1.b', 'all_modules.21.NIN_2.W', 'all_modules.21.NIN_2.b', 'all_modules.21.NIN_3.W', 'all_modules.21.NIN_3.b', 'all_modules.22.GroupNorm_0.weight', 'all_modules.22.GroupNorm_0.bias', 'all_modules.22.Conv_0.weight', 'all_modules.22.Conv_0.bias', 'all_modules.22.Dense_0.weight', 'all_modules.22.Dense_0.bias', 'all_modules.22.GroupNorm_1.weight', 'all_modules.22.GroupNorm_1.bias', 'all_modules.22.Conv_1.weight', 'all_modules.22.Conv_1.bias', 'all_modules.23.GroupNorm_0.weight', 'all_modules.23.GroupNorm_0.bias', 'all_modules.23.Conv_0.weight', 'all_modules.23.Conv_0.bias', 'all_modules.23.Dense_0.weight', 'all_modules.23.Dense_0.bias', 'all_modules.23.GroupNorm_1.weight', 'all_modules.23.GroupNorm_1.bias', 'all_modules.23.Conv_1.weight', 'all_modules.23.Conv_1.bias', 'all_modules.23.Conv_2.weight', 'all_modules.23.Conv_2.bias', 'all_modules.24.GroupNorm_0.weight', 'all_modules.24.GroupNorm_0.bias', 'all_modules.24.Conv_0.weight', 'all_modules.24.Conv_0.bias', 'all_modules.24.Dense_0.weight', 'all_modules.24.Dense_0.bias', 'all_modules.24.GroupNorm_1.weight', 'all_modules.24.GroupNorm_1.bias', 'all_modules.24.Conv_1.weight', 'all_modules.24.Conv_1.bias', 'all_modules.24.Conv_2.weight', 'all_modules.24.Conv_2.bias', 'all_modules.25.GroupNorm_0.weight', 'all_modules.25.GroupNorm_0.bias', 'all_modules.25.Conv_0.weight', 'all_modules.25.Conv_0.bias', 'all_modules.25.Dense_0.weight', 'all_modules.25.Dense_0.bias', 'all_modules.25.GroupNorm_1.weight', 'all_modules.25.GroupNorm_1.bias', 'all_modules.25.Conv_1.weight', 'all_modules.25.Conv_1.bias', 'all_modules.25.Conv_2.weight', 'all_modules.25.Conv_2.bias', 'all_modules.26.GroupNorm_0.weight', 'all_modules.26.GroupNorm_0.bias', 'all_modules.26.NIN_0.W', 'all_modules.26.NIN_0.b', 'all_modules.26.NIN_1.W', 'all_modules.26.NIN_1.b', 'all_modules.26.NIN_2.W', 'all_modules.26.NIN_2.b', 'all_modules.26.NIN_3.W', 'all_modules.26.NIN_3.b', 'all_modules.27.weight', 'all_modules.27.bias', 'all_modules.28.weight', 'all_modules.28.bias', 'all_modules.29.GroupNorm_0.weight', 'all_modules.29.GroupNorm_0.bias', 'all_modules.29.Conv_0.weight', 'all_modules.29.Conv_0.bias', 'all_modules.29.Dense_0.weight', 'all_modules.29.Dense_0.bias', 'all_modules.29.GroupNorm_1.weight', 'all_modules.29.GroupNorm_1.bias', 'all_modules.29.Conv_1.weight', 'all_modules.29.Conv_1.bias', 'all_modules.29.Conv_2.weight', 'all_modules.29.Conv_2.bias', 'all_modules.30.GroupNorm_0.weight', 'all_modules.30.GroupNorm_0.bias', 'all_modules.30.Conv_0.weight', 'all_modules.30.Conv_0.bias', 'all_modules.30.Dense_0.weight', 'all_modules.30.Dense_0.bias', 'all_modules.30.GroupNorm_1.weight', 'all_modules.30.GroupNorm_1.bias', 'all_modules.30.Conv_1.weight', 'all_modules.30.Conv_1.bias', 'all_modules.30.Conv_2.weight', 'all_modules.30.Conv_2.bias', 'all_modules.31.GroupNorm_0.weight', 'all_modules.31.GroupNorm_0.bias', 'all_modules.31.Conv_0.weight', 'all_modules.31.Conv_0.bias', 'all_modules.31.Dense_0.weight', 'all_modules.31.Dense_0.bias', 'all_modules.31.GroupNorm_1.weight', 'all_modules.31.GroupNorm_1.bias', 'all_modules.31.Conv_1.weight', 'all_modules.31.Conv_1.bias', 'all_modules.31.Conv_2.weight', 'all_modules.31.Conv_2.bias', 'all_modules.32.GroupNorm_0.weight', 'all_modules.32.GroupNorm_0.bias', 'all_modules.32.Conv_0.weight', 'all_modules.32.Conv_0.bias', 'all_modules.32.Dense_0.weight', 'all_modules.32.Dense_0.bias', 'all_modules.32.GroupNorm_1.weight', 'all_modules.32.GroupNorm_1.bias', 'all_modules.32.Conv_1.weight', 'all_modules.32.Conv_1.bias', 'all_modules.32.Conv_2.weight', 'all_modules.32.Conv_2.bias', 'all_modules.33.weight', 'all_modules.33.bias', 'all_modules.34.weight', 'all_modules.34.bias', 'all_modules.35.GroupNorm_0.weight', 'all_modules.35.GroupNorm_0.bias', 'all_modules.35.Conv_0.weight', 'all_modules.35.Conv_0.bias', 'all_modules.35.Dense_0.weight', 'all_modules.35.Dense_0.bias', 'all_modules.35.GroupNorm_1.weight', 'all_modules.35.GroupNorm_1.bias', 'all_modules.35.Conv_1.weight', 'all_modules.35.Conv_1.bias', 'all_modules.35.Conv_2.weight', 'all_modules.35.Conv_2.bias', 'all_modules.36.GroupNorm_0.weight', 'all_modules.36.GroupNorm_0.bias', 'all_modules.36.Conv_0.weight', 'all_modules.36.Conv_0.bias', 'all_modules.36.Dense_0.weight', 'all_modules.36.Dense_0.bias', 'all_modules.36.GroupNorm_1.weight', 'all_modules.36.GroupNorm_1.bias', 'all_modules.36.Conv_1.weight', 'all_modules.36.Conv_1.bias', 'all_modules.36.Conv_2.weight', 'all_modules.36.Conv_2.bias', 'all_modules.37.GroupNorm_0.weight', 'all_modules.37.GroupNorm_0.bias', 'all_modules.37.Conv_0.weight', 'all_modules.37.Conv_0.bias', 'all_modules.37.Dense_0.weight', 'all_modules.37.Dense_0.bias', 'all_modules.37.GroupNorm_1.weight', 'all_modules.37.GroupNorm_1.bias', 'all_modules.37.Conv_1.weight', 'all_modules.37.Conv_1.bias', 'all_modules.37.Conv_2.weight', 'all_modules.37.Conv_2.bias', 'all_modules.38.GroupNorm_0.weight', 'all_modules.38.GroupNorm_0.bias', 'all_modules.38.Conv_0.weight', 'all_modules.38.Conv_0.bias', 'all_modules.38.Dense_0.weight', 'all_modules.38.Dense_0.bias', 'all_modules.38.GroupNorm_1.weight', 'all_modules.38.GroupNorm_1.bias', 'all_modules.38.Conv_1.weight', 'all_modules.38.Conv_1.bias', 'all_modules.38.Conv_2.weight', 'all_modules.38.Conv_2.bias', 'all_modules.39.weight', 'all_modules.39.bias', 'all_modules.40.weight', 'all_modules.40.bias', 'all_modules.41.GroupNorm_0.weight', 'all_modules.41.GroupNorm_0.bias', 'all_modules.41.Conv_0.weight', 'all_modules.41.Conv_0.bias', 'all_modules.41.Dense_0.weight', 'all_modules.41.Dense_0.bias', 'all_modules.41.GroupNorm_1.weight', 'all_modules.41.GroupNorm_1.bias', 'all_modules.41.Conv_1.weight', 'all_modules.41.Conv_1.bias', 'all_modules.41.Conv_2.weight', 'all_modules.41.Conv_2.bias', 'all_modules.42.GroupNorm_0.weight', 'all_modules.42.GroupNorm_0.bias', 'all_modules.42.Conv_0.weight', 'all_modules.42.Conv_0.bias', 'all_modules.42.Dense_0.weight', 'all_modules.42.Dense_0.bias', 'all_modules.42.GroupNorm_1.weight', 'all_modules.42.GroupNorm_1.bias', 'all_modules.42.Conv_1.weight', 'all_modules.42.Conv_1.bias', 'all_modules.42.Conv_2.weight', 'all_modules.42.Conv_2.bias', 'all_modules.43.GroupNorm_0.weight', 'all_modules.43.GroupNorm_0.bias', 'all_modules.43.Conv_0.weight', 'all_modules.43.Conv_0.bias', 'all_modules.43.Dense_0.weight', 'all_modules.43.Dense_0.bias', 'all_modules.43.GroupNorm_1.weight', 'all_modules.43.GroupNorm_1.bias', 'all_modules.43.Conv_1.weight', 'all_modules.43.Conv_1.bias', 'all_modules.43.Conv_2.weight', 'all_modules.43.Conv_2.bias', 'all_modules.44.GroupNorm_0.weight', 'all_modules.44.GroupNorm_0.bias', 'all_modules.44.Conv_0.weight', 'all_modules.44.Conv_0.bias', 'all_modules.44.Dense_0.weight', 'all_modules.44.Dense_0.bias', 'all_modules.44.GroupNorm_1.weight', 'all_modules.44.GroupNorm_1.bias', 'all_modules.44.Conv_1.weight', 'all_modules.44.Conv_1.bias', 'all_modules.44.Conv_2.weight', 'all_modules.44.Conv_2.bias', 'all_modules.45.weight', 'all_modules.45.bias', 'all_modules.46.weight', 'all_modules.46.bias'])\n",
      "odict_keys(['sigmas', 'all_modules.0.W', 'all_modules.1.weight', 'all_modules.1.bias', 'all_modules.1.lora_A', 'all_modules.1.lora_B', 'all_modules.2.weight', 'all_modules.2.bias', 'all_modules.2.lora_A', 'all_modules.2.lora_B', 'all_modules.3.weight', 'all_modules.3.bias', 'all_modules.4.GroupNorm_0.weight', 'all_modules.4.GroupNorm_0.bias', 'all_modules.4.Conv_0.weight', 'all_modules.4.Conv_0.bias', 'all_modules.4.Dense_0.weight', 'all_modules.4.Dense_0.bias', 'all_modules.4.GroupNorm_1.weight', 'all_modules.4.GroupNorm_1.bias', 'all_modules.4.Conv_1.weight', 'all_modules.4.Conv_1.bias', 'all_modules.5.GroupNorm_0.weight', 'all_modules.5.GroupNorm_0.bias', 'all_modules.5.Conv_0.weight', 'all_modules.5.Conv_0.bias', 'all_modules.5.Dense_0.weight', 'all_modules.5.Dense_0.bias', 'all_modules.5.GroupNorm_1.weight', 'all_modules.5.GroupNorm_1.bias', 'all_modules.5.Conv_1.weight', 'all_modules.5.Conv_1.bias', 'all_modules.6.GroupNorm_0.weight', 'all_modules.6.GroupNorm_0.bias', 'all_modules.6.Conv_0.weight', 'all_modules.6.Conv_0.bias', 'all_modules.6.Dense_0.weight', 'all_modules.6.Dense_0.bias', 'all_modules.6.GroupNorm_1.weight', 'all_modules.6.GroupNorm_1.bias', 'all_modules.6.Conv_1.weight', 'all_modules.6.Conv_1.bias', 'all_modules.6.Conv_2.weight', 'all_modules.6.Conv_2.bias', 'all_modules.7.Conv_0.weight', 'all_modules.7.Conv_0.bias', 'all_modules.8.GroupNorm_0.weight', 'all_modules.8.GroupNorm_0.bias', 'all_modules.8.Conv_0.weight', 'all_modules.8.Conv_0.bias', 'all_modules.8.Dense_0.weight', 'all_modules.8.Dense_0.bias', 'all_modules.8.GroupNorm_1.weight', 'all_modules.8.GroupNorm_1.bias', 'all_modules.8.Conv_1.weight', 'all_modules.8.Conv_1.bias', 'all_modules.9.GroupNorm_0.weight', 'all_modules.9.GroupNorm_0.bias', 'all_modules.9.Conv_0.weight', 'all_modules.9.Conv_0.bias', 'all_modules.9.Dense_0.weight', 'all_modules.9.Dense_0.bias', 'all_modules.9.GroupNorm_1.weight', 'all_modules.9.GroupNorm_1.bias', 'all_modules.9.Conv_1.weight', 'all_modules.9.Conv_1.bias', 'all_modules.10.GroupNorm_0.weight', 'all_modules.10.GroupNorm_0.bias', 'all_modules.10.Conv_0.weight', 'all_modules.10.Conv_0.bias', 'all_modules.10.Dense_0.weight', 'all_modules.10.Dense_0.bias', 'all_modules.10.GroupNorm_1.weight', 'all_modules.10.GroupNorm_1.bias', 'all_modules.10.Conv_1.weight', 'all_modules.10.Conv_1.bias', 'all_modules.10.Conv_2.weight', 'all_modules.10.Conv_2.bias', 'all_modules.11.Conv_0.weight', 'all_modules.11.Conv_0.bias', 'all_modules.12.GroupNorm_0.weight', 'all_modules.12.GroupNorm_0.bias', 'all_modules.12.Conv_0.weight', 'all_modules.12.Conv_0.bias', 'all_modules.12.Dense_0.weight', 'all_modules.12.Dense_0.bias', 'all_modules.12.GroupNorm_1.weight', 'all_modules.12.GroupNorm_1.bias', 'all_modules.12.Conv_1.weight', 'all_modules.12.Conv_1.bias', 'all_modules.12.Conv_2.weight', 'all_modules.12.Conv_2.bias', 'all_modules.13.GroupNorm_0.weight', 'all_modules.13.GroupNorm_0.bias', 'all_modules.13.Conv_0.weight', 'all_modules.13.Conv_0.bias', 'all_modules.13.Dense_0.weight', 'all_modules.13.Dense_0.bias', 'all_modules.13.GroupNorm_1.weight', 'all_modules.13.GroupNorm_1.bias', 'all_modules.13.Conv_1.weight', 'all_modules.13.Conv_1.bias', 'all_modules.14.GroupNorm_0.weight', 'all_modules.14.GroupNorm_0.bias', 'all_modules.14.Conv_0.weight', 'all_modules.14.Conv_0.bias', 'all_modules.14.Dense_0.weight', 'all_modules.14.Dense_0.bias', 'all_modules.14.GroupNorm_1.weight', 'all_modules.14.GroupNorm_1.bias', 'all_modules.14.Conv_1.weight', 'all_modules.14.Conv_1.bias', 'all_modules.14.Conv_2.weight', 'all_modules.14.Conv_2.bias', 'all_modules.15.Conv_0.weight', 'all_modules.15.Conv_0.bias', 'all_modules.16.GroupNorm_0.weight', 'all_modules.16.GroupNorm_0.bias', 'all_modules.16.Conv_0.weight', 'all_modules.16.Conv_0.bias', 'all_modules.16.Dense_0.weight', 'all_modules.16.Dense_0.bias', 'all_modules.16.GroupNorm_1.weight', 'all_modules.16.GroupNorm_1.bias', 'all_modules.16.Conv_1.weight', 'all_modules.16.Conv_1.bias', 'all_modules.17.GroupNorm_0.weight', 'all_modules.17.GroupNorm_0.bias', 'all_modules.17.NIN_0.W', 'all_modules.17.NIN_0.b', 'all_modules.17.NIN_1.W', 'all_modules.17.NIN_1.b', 'all_modules.17.NIN_2.W', 'all_modules.17.NIN_2.b', 'all_modules.17.NIN_3.W', 'all_modules.17.NIN_3.b', 'all_modules.18.GroupNorm_0.weight', 'all_modules.18.GroupNorm_0.bias', 'all_modules.18.Conv_0.weight', 'all_modules.18.Conv_0.bias', 'all_modules.18.Dense_0.weight', 'all_modules.18.Dense_0.bias', 'all_modules.18.GroupNorm_1.weight', 'all_modules.18.GroupNorm_1.bias', 'all_modules.18.Conv_1.weight', 'all_modules.18.Conv_1.bias', 'all_modules.19.GroupNorm_0.weight', 'all_modules.19.GroupNorm_0.bias', 'all_modules.19.NIN_0.W', 'all_modules.19.NIN_0.b', 'all_modules.19.NIN_1.W', 'all_modules.19.NIN_1.b', 'all_modules.19.NIN_2.W', 'all_modules.19.NIN_2.b', 'all_modules.19.NIN_3.W', 'all_modules.19.NIN_3.b', 'all_modules.20.GroupNorm_0.weight', 'all_modules.20.GroupNorm_0.bias', 'all_modules.20.Conv_0.weight', 'all_modules.20.Conv_0.bias', 'all_modules.20.Dense_0.weight', 'all_modules.20.Dense_0.bias', 'all_modules.20.GroupNorm_1.weight', 'all_modules.20.GroupNorm_1.bias', 'all_modules.20.Conv_1.weight', 'all_modules.20.Conv_1.bias', 'all_modules.21.GroupNorm_0.weight', 'all_modules.21.GroupNorm_0.bias', 'all_modules.21.NIN_0.W', 'all_modules.21.NIN_0.b', 'all_modules.21.NIN_1.W', 'all_modules.21.NIN_1.b', 'all_modules.21.NIN_2.W', 'all_modules.21.NIN_2.b', 'all_modules.21.NIN_3.W', 'all_modules.21.NIN_3.b', 'all_modules.22.GroupNorm_0.weight', 'all_modules.22.GroupNorm_0.bias', 'all_modules.22.Conv_0.weight', 'all_modules.22.Conv_0.bias', 'all_modules.22.Conv_0.lora_A', 'all_modules.22.Conv_0.lora_B', 'all_modules.22.Dense_0.weight', 'all_modules.22.Dense_0.bias', 'all_modules.22.GroupNorm_1.weight', 'all_modules.22.GroupNorm_1.bias', 'all_modules.22.Conv_1.weight', 'all_modules.22.Conv_1.bias', 'all_modules.22.Conv_1.lora_A', 'all_modules.22.Conv_1.lora_B', 'all_modules.23.GroupNorm_0.weight', 'all_modules.23.GroupNorm_0.bias', 'all_modules.23.Conv_0.weight', 'all_modules.23.Conv_0.bias', 'all_modules.23.Dense_0.weight', 'all_modules.23.Dense_0.bias', 'all_modules.23.GroupNorm_1.weight', 'all_modules.23.GroupNorm_1.bias', 'all_modules.23.Conv_1.weight', 'all_modules.23.Conv_1.bias', 'all_modules.23.Conv_2.weight', 'all_modules.23.Conv_2.bias', 'all_modules.24.GroupNorm_0.weight', 'all_modules.24.GroupNorm_0.bias', 'all_modules.24.Conv_0.weight', 'all_modules.24.Conv_0.bias', 'all_modules.24.Conv_0.lora_A', 'all_modules.24.Conv_0.lora_B', 'all_modules.24.Dense_0.weight', 'all_modules.24.Dense_0.bias', 'all_modules.24.GroupNorm_1.weight', 'all_modules.24.GroupNorm_1.bias', 'all_modules.24.Conv_1.weight', 'all_modules.24.Conv_1.bias', 'all_modules.24.Conv_1.lora_A', 'all_modules.24.Conv_1.lora_B', 'all_modules.24.Conv_2.weight', 'all_modules.24.Conv_2.bias', 'all_modules.25.GroupNorm_0.weight', 'all_modules.25.GroupNorm_0.bias', 'all_modules.25.Conv_0.weight', 'all_modules.25.Conv_0.bias', 'all_modules.25.Dense_0.weight', 'all_modules.25.Dense_0.bias', 'all_modules.25.GroupNorm_1.weight', 'all_modules.25.GroupNorm_1.bias', 'all_modules.25.Conv_1.weight', 'all_modules.25.Conv_1.bias', 'all_modules.25.Conv_2.weight', 'all_modules.25.Conv_2.bias', 'all_modules.26.GroupNorm_0.weight', 'all_modules.26.GroupNorm_0.bias', 'all_modules.26.NIN_0.W', 'all_modules.26.NIN_0.b', 'all_modules.26.NIN_1.W', 'all_modules.26.NIN_1.b', 'all_modules.26.NIN_2.W', 'all_modules.26.NIN_2.b', 'all_modules.26.NIN_3.W', 'all_modules.26.NIN_3.b', 'all_modules.27.weight', 'all_modules.27.bias', 'all_modules.28.weight', 'all_modules.28.bias', 'all_modules.29.GroupNorm_0.weight', 'all_modules.29.GroupNorm_0.bias', 'all_modules.29.Conv_0.weight', 'all_modules.29.Conv_0.bias', 'all_modules.29.Dense_0.weight', 'all_modules.29.Dense_0.bias', 'all_modules.29.GroupNorm_1.weight', 'all_modules.29.GroupNorm_1.bias', 'all_modules.29.Conv_1.weight', 'all_modules.29.Conv_1.bias', 'all_modules.29.Conv_2.weight', 'all_modules.29.Conv_2.bias', 'all_modules.30.GroupNorm_0.weight', 'all_modules.30.GroupNorm_0.bias', 'all_modules.30.Conv_0.weight', 'all_modules.30.Conv_0.bias', 'all_modules.30.Dense_0.weight', 'all_modules.30.Dense_0.bias', 'all_modules.30.GroupNorm_1.weight', 'all_modules.30.GroupNorm_1.bias', 'all_modules.30.Conv_1.weight', 'all_modules.30.Conv_1.bias', 'all_modules.30.Conv_2.weight', 'all_modules.30.Conv_2.bias', 'all_modules.31.GroupNorm_0.weight', 'all_modules.31.GroupNorm_0.bias', 'all_modules.31.Conv_0.weight', 'all_modules.31.Conv_0.bias', 'all_modules.31.Conv_0.lora_A', 'all_modules.31.Conv_0.lora_B', 'all_modules.31.Dense_0.weight', 'all_modules.31.Dense_0.bias', 'all_modules.31.GroupNorm_1.weight', 'all_modules.31.GroupNorm_1.bias', 'all_modules.31.Conv_1.weight', 'all_modules.31.Conv_1.bias', 'all_modules.31.Conv_1.lora_A', 'all_modules.31.Conv_1.lora_B', 'all_modules.31.Conv_2.weight', 'all_modules.31.Conv_2.bias', 'all_modules.32.GroupNorm_0.weight', 'all_modules.32.GroupNorm_0.bias', 'all_modules.32.Conv_0.weight', 'all_modules.32.Conv_0.bias', 'all_modules.32.Dense_0.weight', 'all_modules.32.Dense_0.bias', 'all_modules.32.GroupNorm_1.weight', 'all_modules.32.GroupNorm_1.bias', 'all_modules.32.Conv_1.weight', 'all_modules.32.Conv_1.bias', 'all_modules.32.Conv_2.weight', 'all_modules.32.Conv_2.bias', 'all_modules.33.weight', 'all_modules.33.bias', 'all_modules.34.weight', 'all_modules.34.bias', 'all_modules.34.lora_A', 'all_modules.34.lora_B', 'all_modules.35.GroupNorm_0.weight', 'all_modules.35.GroupNorm_0.bias', 'all_modules.35.Conv_0.weight', 'all_modules.35.Conv_0.bias', 'all_modules.35.Dense_0.weight', 'all_modules.35.Dense_0.bias', 'all_modules.35.GroupNorm_1.weight', 'all_modules.35.GroupNorm_1.bias', 'all_modules.35.Conv_1.weight', 'all_modules.35.Conv_1.bias', 'all_modules.35.Conv_2.weight', 'all_modules.35.Conv_2.bias', 'all_modules.36.GroupNorm_0.weight', 'all_modules.36.GroupNorm_0.bias', 'all_modules.36.Conv_0.weight', 'all_modules.36.Conv_0.bias', 'all_modules.36.Dense_0.weight', 'all_modules.36.Dense_0.bias', 'all_modules.36.GroupNorm_1.weight', 'all_modules.36.GroupNorm_1.bias', 'all_modules.36.Conv_1.weight', 'all_modules.36.Conv_1.bias', 'all_modules.36.Conv_2.weight', 'all_modules.36.Conv_2.bias', 'all_modules.37.GroupNorm_0.weight', 'all_modules.37.GroupNorm_0.bias', 'all_modules.37.Conv_0.weight', 'all_modules.37.Conv_0.bias', 'all_modules.37.Conv_0.lora_A', 'all_modules.37.Conv_0.lora_B', 'all_modules.37.Dense_0.weight', 'all_modules.37.Dense_0.bias', 'all_modules.37.GroupNorm_1.weight', 'all_modules.37.GroupNorm_1.bias', 'all_modules.37.Conv_1.weight', 'all_modules.37.Conv_1.bias', 'all_modules.37.Conv_1.lora_A', 'all_modules.37.Conv_1.lora_B', 'all_modules.37.Conv_2.weight', 'all_modules.37.Conv_2.bias', 'all_modules.38.GroupNorm_0.weight', 'all_modules.38.GroupNorm_0.bias', 'all_modules.38.Conv_0.weight', 'all_modules.38.Conv_0.bias', 'all_modules.38.Dense_0.weight', 'all_modules.38.Dense_0.bias', 'all_modules.38.GroupNorm_1.weight', 'all_modules.38.GroupNorm_1.bias', 'all_modules.38.Conv_1.weight', 'all_modules.38.Conv_1.bias', 'all_modules.38.Conv_2.weight', 'all_modules.38.Conv_2.bias', 'all_modules.39.weight', 'all_modules.39.bias', 'all_modules.40.weight', 'all_modules.40.bias', 'all_modules.40.lora_A', 'all_modules.40.lora_B', 'all_modules.41.GroupNorm_0.weight', 'all_modules.41.GroupNorm_0.bias', 'all_modules.41.Conv_0.weight', 'all_modules.41.Conv_0.bias', 'all_modules.41.Dense_0.weight', 'all_modules.41.Dense_0.bias', 'all_modules.41.GroupNorm_1.weight', 'all_modules.41.GroupNorm_1.bias', 'all_modules.41.Conv_1.weight', 'all_modules.41.Conv_1.bias', 'all_modules.41.Conv_2.weight', 'all_modules.41.Conv_2.bias', 'all_modules.42.GroupNorm_0.weight', 'all_modules.42.GroupNorm_0.bias', 'all_modules.42.Conv_0.weight', 'all_modules.42.Conv_0.bias', 'all_modules.42.Dense_0.weight', 'all_modules.42.Dense_0.bias', 'all_modules.42.GroupNorm_1.weight', 'all_modules.42.GroupNorm_1.bias', 'all_modules.42.Conv_1.weight', 'all_modules.42.Conv_1.bias', 'all_modules.42.Conv_2.weight', 'all_modules.42.Conv_2.bias', 'all_modules.43.GroupNorm_0.weight', 'all_modules.43.GroupNorm_0.bias', 'all_modules.43.Conv_0.weight', 'all_modules.43.Conv_0.bias', 'all_modules.43.Conv_0.lora_A', 'all_modules.43.Conv_0.lora_B', 'all_modules.43.Dense_0.weight', 'all_modules.43.Dense_0.bias', 'all_modules.43.GroupNorm_1.weight', 'all_modules.43.GroupNorm_1.bias', 'all_modules.43.Conv_1.weight', 'all_modules.43.Conv_1.bias', 'all_modules.43.Conv_1.lora_A', 'all_modules.43.Conv_1.lora_B', 'all_modules.43.Conv_2.weight', 'all_modules.43.Conv_2.bias', 'all_modules.44.GroupNorm_0.weight', 'all_modules.44.GroupNorm_0.bias', 'all_modules.44.Conv_0.weight', 'all_modules.44.Conv_0.bias', 'all_modules.44.Dense_0.weight', 'all_modules.44.Dense_0.bias', 'all_modules.44.GroupNorm_1.weight', 'all_modules.44.GroupNorm_1.bias', 'all_modules.44.Conv_1.weight', 'all_modules.44.Conv_1.bias', 'all_modules.44.Conv_2.weight', 'all_modules.44.Conv_2.bias', 'all_modules.45.weight', 'all_modules.45.bias', 'all_modules.46.weight', 'all_modules.46.bias', 'all_modules.46.lora_A', 'all_modules.46.lora_B'])\n"
     ]
    }
   ],
   "source": [
    "print(loaded_state.keys())\n",
    "print(afhq_lora_dog_model.network.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afhq_lora_dog_model.network.load_state_dict(loaded_state, strict=False)\n",
    "((afhq_lora_dog_model.network.state_dict()[\"all_modules.1.weight\"] - loaded_state[\"all_modules.1.weight\"]) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_only_lora_as_trainable(afhq_lora_dog_model.network, bias=\"all\")\n",
    "for name , p in list(afhq_lora_dog_model.network.named_parameters()):\n",
    "    print(f\"{name}: {p.requires_grad}\")\n",
    "    if \"lora_\" in name:\n",
    "        print(p, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_modules.43.Conv_1.lora_A', 'all_modules.41.Conv_0.lora_A', 'all_modules.43.Conv_1.lora_B', 'all_modules.5.Conv_0.lora_B', 'all_modules.38.Conv_0.lora_A', 'all_modules.26.NIN_0.lora_A', 'all_modules.36.Conv_0.lora_A', 'all_modules.5.Conv_0.lora_A', 'all_modules.4.Conv_1.lora_A', 'all_modules.25.Conv_1.lora_A', 'all_modules.41.Conv_1.lora_A', 'all_modules.13.Conv_0.lora_B', 'all_modules.21.NIN_0.lora_A', 'all_modules.37.Conv_0.lora_B', 'all_modules.19.NIN_0.lora_B', 'all_modules.10.Conv_1.lora_A', 'all_modules.19.NIN_2.lora_B', 'all_modules.20.Conv_1.lora_A', 'all_modules.24.Conv_1.lora_A', 'all_modules.40.lora_B', 'all_modules.31.Conv_1.lora_A', 'all_modules.6.Conv_0.lora_A', 'all_modules.22.Conv_0.lora_A', 'all_modules.20.Conv_1.lora_B', 'all_modules.16.Conv_0.lora_A', 'all_modules.44.Conv_0.lora_B', 'all_modules.37.Conv_0.lora_A', 'all_modules.21.NIN_1.lora_B', 'all_modules.38.Conv_1.lora_B', 'all_modules.8.Conv_0.lora_A', 'all_modules.23.Conv_1.lora_A', 'all_modules.19.NIN_3.lora_B', 'all_modules.17.NIN_2.lora_A', 'all_modules.38.Conv_0.lora_B', 'all_modules.31.Conv_0.lora_B', 'all_modules.13.Conv_1.lora_B', 'all_modules.26.NIN_0.lora_B', 'all_modules.41.Conv_1.lora_B', 'all_modules.14.Conv_1.lora_A', 'all_modules.23.Conv_0.lora_A', 'all_modules.46.lora_A', 'all_modules.5.Conv_1.lora_B', 'all_modules.24.Conv_0.lora_A', 'all_modules.31.Conv_0.lora_A', 'all_modules.24.Conv_1.lora_B', 'all_modules.6.Conv_1.lora_A', 'all_modules.17.NIN_1.lora_A', 'all_modules.18.Conv_1.lora_B', 'all_modules.30.Conv_0.lora_A', 'all_modules.12.Conv_1.lora_A', 'all_modules.42.Conv_0.lora_B', 'all_modules.25.Conv_1.lora_B', 'all_modules.17.NIN_3.lora_A', 'all_modules.44.Conv_1.lora_B', 'all_modules.21.NIN_3.lora_B', 'all_modules.35.Conv_1.lora_A', 'all_modules.25.Conv_0.lora_A', 'all_modules.5.Conv_1.lora_A', 'all_modules.14.Conv_1.lora_B', 'all_modules.36.Conv_0.lora_B', 'all_modules.2.lora_A', 'all_modules.13.Conv_1.lora_A', 'all_modules.4.Conv_0.lora_A', 'all_modules.36.Conv_1.lora_A', 'all_modules.6.Conv_1.lora_B', 'all_modules.10.Conv_1.lora_B', 'all_modules.41.Conv_0.lora_B', 'all_modules.12.Conv_0.lora_B', 'all_modules.13.Conv_0.lora_A', 'all_modules.14.Conv_0.lora_B', 'all_modules.35.Conv_0.lora_B', 'all_modules.17.NIN_3.lora_B', 'all_modules.31.Conv_1.lora_B', 'all_modules.18.Conv_1.lora_A', 'all_modules.1.lora_A', 'all_modules.19.NIN_3.lora_A', 'all_modules.25.Conv_0.lora_B', 'all_modules.26.NIN_3.lora_A', 'all_modules.18.Conv_0.lora_B', 'all_modules.16.Conv_1.lora_B', 'all_modules.9.Conv_0.lora_B', 'all_modules.19.NIN_0.lora_A', 'all_modules.21.NIN_1.lora_A', 'all_modules.30.Conv_1.lora_B', 'all_modules.43.Conv_0.lora_B', 'all_modules.21.NIN_2.lora_A', 'all_modules.17.NIN_1.lora_B', 'all_modules.24.Conv_0.lora_B', 'all_modules.38.Conv_1.lora_A', 'all_modules.18.Conv_0.lora_A', 'all_modules.12.Conv_0.lora_A', 'all_modules.29.Conv_0.lora_B', 'all_modules.21.NIN_2.lora_B', 'all_modules.20.Conv_0.lora_A', 'all_modules.44.Conv_1.lora_A', 'all_modules.35.Conv_1.lora_B', 'all_modules.40.lora_A', 'all_modules.19.NIN_1.lora_B', 'all_modules.8.Conv_1.lora_B', 'all_modules.42.Conv_1.lora_B', 'all_modules.4.Conv_0.lora_B', 'all_modules.36.Conv_1.lora_B', 'all_modules.8.Conv_1.lora_A', 'all_modules.35.Conv_0.lora_A', 'all_modules.42.Conv_0.lora_A', 'all_modules.9.Conv_1.lora_B', 'all_modules.1.lora_B', 'all_modules.44.Conv_0.lora_A', 'all_modules.32.Conv_0.lora_B', 'all_modules.8.Conv_0.lora_B', 'all_modules.29.Conv_0.lora_A', 'all_modules.9.Conv_1.lora_A', 'all_modules.19.NIN_1.lora_A', 'all_modules.32.Conv_1.lora_A', 'all_modules.32.Conv_0.lora_A', 'all_modules.16.Conv_0.lora_B', 'all_modules.20.Conv_0.lora_B', 'all_modules.29.Conv_1.lora_A', 'all_modules.6.Conv_0.lora_B', 'all_modules.34.lora_B', 'all_modules.19.NIN_2.lora_A', 'all_modules.42.Conv_1.lora_A', 'all_modules.22.Conv_1.lora_A', 'all_modules.26.NIN_2.lora_B', 'all_modules.23.Conv_0.lora_B', 'all_modules.26.NIN_2.lora_A', 'all_modules.29.Conv_1.lora_B', 'all_modules.2.lora_B', 'all_modules.21.NIN_3.lora_A', 'all_modules.22.Conv_0.lora_B', 'all_modules.10.Conv_0.lora_B', 'all_modules.26.NIN_3.lora_B', 'all_modules.16.Conv_1.lora_A', 'all_modules.17.NIN_0.lora_B', 'all_modules.21.NIN_0.lora_B', 'all_modules.46.lora_B', 'all_modules.30.Conv_1.lora_A', 'all_modules.14.Conv_0.lora_A', 'all_modules.30.Conv_0.lora_B', 'all_modules.22.Conv_1.lora_B', 'all_modules.26.NIN_1.lora_B', 'all_modules.34.lora_A', 'all_modules.10.Conv_0.lora_A', 'all_modules.9.Conv_0.lora_A', 'all_modules.12.Conv_1.lora_B', 'all_modules.23.Conv_1.lora_B', 'all_modules.4.Conv_1.lora_B', 'all_modules.37.Conv_1.lora_B', 'all_modules.26.NIN_1.lora_A', 'all_modules.32.Conv_1.lora_B', 'all_modules.17.NIN_0.lora_A', 'all_modules.17.NIN_2.lora_B', 'all_modules.43.Conv_0.lora_A', 'all_modules.37.Conv_1.lora_A'}\n",
      "all_modules.1.lora_A\n",
      "tensor(2.8497, device='cuda:0')\n",
      "all_modules.1.lora_B\n",
      "tensor(3.9347, device='cuda:0')\n",
      "all_modules.2.lora_A\n",
      "tensor(6.1244, device='cuda:0')\n",
      "all_modules.2.lora_B\n",
      "tensor(5.3052, device='cuda:0')\n",
      "all_modules.4.Conv_0.weight tensor(2.2120, device='cuda:0')\n",
      "all_modules.4.Conv_0.lora_A\n",
      "tensor(12.3978, device='cuda:0')\n",
      "all_modules.4.Conv_0.lora_B\n",
      "tensor(6.6797, device='cuda:0')\n",
      "all_modules.4.Conv_1.weight tensor(0.9377, device='cuda:0')\n",
      "all_modules.4.Conv_1.lora_A\n",
      "tensor(5.3375, device='cuda:0')\n",
      "all_modules.4.Conv_1.lora_B\n",
      "tensor(2.5884, device='cuda:0')\n",
      "all_modules.5.Conv_0.weight tensor(2.6048, device='cuda:0')\n",
      "all_modules.5.Conv_0.lora_A\n",
      "tensor(14.0748, device='cuda:0')\n",
      "all_modules.5.Conv_0.lora_B\n",
      "tensor(6.9866, device='cuda:0')\n",
      "all_modules.5.Conv_1.weight tensor(1.9818, device='cuda:0')\n",
      "all_modules.5.Conv_1.lora_A\n",
      "tensor(8.5929, device='cuda:0')\n",
      "all_modules.5.Conv_1.lora_B\n",
      "tensor(3.6310, device='cuda:0')\n",
      "all_modules.6.Conv_0.weight tensor(4.7255, device='cuda:0')\n",
      "all_modules.6.Conv_0.lora_A\n",
      "tensor(19.1582, device='cuda:0')\n",
      "all_modules.6.Conv_0.lora_B\n",
      "tensor(9.6128, device='cuda:0')\n",
      "all_modules.6.Conv_1.weight tensor(2.7094, device='cuda:0')\n",
      "all_modules.6.Conv_1.lora_A\n",
      "tensor(10.5233, device='cuda:0')\n",
      "all_modules.6.Conv_1.lora_B\n",
      "tensor(5.5301, device='cuda:0')\n",
      "all_modules.8.Conv_0.weight tensor(4.9542, device='cuda:0')\n",
      "all_modules.8.Conv_0.lora_A\n",
      "tensor(17.2208, device='cuda:0')\n",
      "all_modules.8.Conv_0.lora_B\n",
      "tensor(7.9799, device='cuda:0')\n",
      "all_modules.8.Conv_1.weight tensor(3.9028, device='cuda:0')\n",
      "all_modules.8.Conv_1.lora_A\n",
      "tensor(13.1722, device='cuda:0')\n",
      "all_modules.8.Conv_1.lora_B\n",
      "tensor(5.5546, device='cuda:0')\n",
      "all_modules.9.Conv_0.weight tensor(3.8759, device='cuda:0')\n",
      "all_modules.9.Conv_0.lora_A\n",
      "tensor(16.1175, device='cuda:0')\n",
      "all_modules.9.Conv_0.lora_B\n",
      "tensor(8.0288, device='cuda:0')\n",
      "all_modules.9.Conv_1.weight tensor(2.9483, device='cuda:0')\n",
      "all_modules.9.Conv_1.lora_A\n",
      "tensor(14.2902, device='cuda:0')\n",
      "all_modules.9.Conv_1.lora_B\n",
      "tensor(5.9510, device='cuda:0')\n",
      "all_modules.10.Conv_0.weight tensor(1.4499, device='cuda:0')\n",
      "all_modules.10.Conv_0.lora_A\n",
      "tensor(9.4461, device='cuda:0')\n",
      "all_modules.10.Conv_0.lora_B\n",
      "tensor(5.4090, device='cuda:0')\n",
      "all_modules.10.Conv_1.weight tensor(1.0499, device='cuda:0')\n",
      "all_modules.10.Conv_1.lora_A\n",
      "tensor(6.3450, device='cuda:0')\n",
      "all_modules.10.Conv_1.lora_B\n",
      "tensor(4.0326, device='cuda:0')\n",
      "all_modules.12.Conv_0.weight tensor(16.4944, device='cuda:0')\n",
      "all_modules.12.Conv_0.lora_A\n",
      "tensor(19.1414, device='cuda:0')\n",
      "all_modules.12.Conv_0.lora_B\n",
      "tensor(17.1891, device='cuda:0')\n",
      "all_modules.12.Conv_1.weight tensor(25.2591, device='cuda:0')\n",
      "all_modules.12.Conv_1.lora_A\n",
      "tensor(29.5274, device='cuda:0')\n",
      "all_modules.12.Conv_1.lora_B\n",
      "tensor(14.3800, device='cuda:0')\n",
      "all_modules.13.Conv_0.weight tensor(66.7251, device='cuda:0')\n",
      "all_modules.13.Conv_0.lora_A\n",
      "tensor(39.9398, device='cuda:0')\n",
      "all_modules.13.Conv_0.lora_B\n",
      "tensor(20.6213, device='cuda:0')\n",
      "all_modules.13.Conv_1.weight tensor(48.7514, device='cuda:0')\n",
      "all_modules.13.Conv_1.lora_A\n",
      "tensor(41.3046, device='cuda:0')\n",
      "all_modules.13.Conv_1.lora_B\n",
      "tensor(17.3658, device='cuda:0')\n",
      "all_modules.14.Conv_0.weight tensor(41.2379, device='cuda:0')\n",
      "all_modules.14.Conv_0.lora_A\n",
      "tensor(35.2913, device='cuda:0')\n",
      "all_modules.14.Conv_0.lora_B\n",
      "tensor(21.8680, device='cuda:0')\n",
      "all_modules.14.Conv_1.weight tensor(30.5288, device='cuda:0')\n",
      "all_modules.14.Conv_1.lora_A\n",
      "tensor(33.4305, device='cuda:0')\n",
      "all_modules.14.Conv_1.lora_B\n",
      "tensor(17.3732, device='cuda:0')\n",
      "all_modules.16.Conv_0.weight tensor(62.8694, device='cuda:0')\n",
      "all_modules.16.Conv_0.lora_A\n",
      "tensor(36.7540, device='cuda:0')\n",
      "all_modules.16.Conv_0.lora_B\n",
      "tensor(23.4401, device='cuda:0')\n",
      "all_modules.16.Conv_1.weight tensor(54.9186, device='cuda:0')\n",
      "all_modules.16.Conv_1.lora_A\n",
      "tensor(36.5346, device='cuda:0')\n",
      "all_modules.16.Conv_1.lora_B\n",
      "tensor(21.6452, device='cuda:0')\n",
      "all_modules.17.NIN_0.lora_A\n",
      "tensor(2.6195, device='cuda:0')\n",
      "all_modules.17.NIN_0.lora_B\n",
      "tensor(1.8901, device='cuda:0')\n",
      "all_modules.17.NIN_1.lora_A\n",
      "tensor(3.1501, device='cuda:0')\n",
      "all_modules.17.NIN_1.lora_B\n",
      "tensor(2.7059, device='cuda:0')\n",
      "all_modules.17.NIN_2.lora_A\n",
      "tensor(2.9388, device='cuda:0')\n",
      "all_modules.17.NIN_2.lora_B\n",
      "tensor(2.2831, device='cuda:0')\n",
      "all_modules.17.NIN_3.lora_A\n",
      "tensor(6.1599, device='cuda:0')\n",
      "all_modules.17.NIN_3.lora_B\n",
      "tensor(1.4781, device='cuda:0')\n",
      "all_modules.18.Conv_0.weight tensor(65.3504, device='cuda:0')\n",
      "all_modules.18.Conv_0.lora_A\n",
      "tensor(32.3587, device='cuda:0')\n",
      "all_modules.18.Conv_0.lora_B\n",
      "tensor(25.3617, device='cuda:0')\n",
      "all_modules.18.Conv_1.weight tensor(56.4919, device='cuda:0')\n",
      "all_modules.18.Conv_1.lora_A\n",
      "tensor(31.3686, device='cuda:0')\n",
      "all_modules.18.Conv_1.lora_B\n",
      "tensor(17.4243, device='cuda:0')\n",
      "all_modules.19.NIN_0.lora_A\n",
      "tensor(2.5336, device='cuda:0')\n",
      "all_modules.19.NIN_0.lora_B\n",
      "tensor(1.3796, device='cuda:0')\n",
      "all_modules.19.NIN_1.lora_A\n",
      "tensor(2.9810, device='cuda:0')\n",
      "all_modules.19.NIN_1.lora_B\n",
      "tensor(3.2801, device='cuda:0')\n",
      "all_modules.19.NIN_2.lora_A\n",
      "tensor(2.0956, device='cuda:0')\n",
      "all_modules.19.NIN_2.lora_B\n",
      "tensor(0.5902, device='cuda:0')\n",
      "all_modules.19.NIN_3.lora_A\n",
      "tensor(7.3750, device='cuda:0')\n",
      "all_modules.19.NIN_3.lora_B\n",
      "tensor(1.5292, device='cuda:0')\n",
      "all_modules.20.Conv_0.weight tensor(67.8518, device='cuda:0')\n",
      "all_modules.20.Conv_0.lora_A\n",
      "tensor(30.4475, device='cuda:0')\n",
      "all_modules.20.Conv_0.lora_B\n",
      "tensor(21.5810, device='cuda:0')\n",
      "all_modules.20.Conv_1.weight tensor(47.9800, device='cuda:0')\n",
      "all_modules.20.Conv_1.lora_A\n",
      "tensor(32.7164, device='cuda:0')\n",
      "all_modules.20.Conv_1.lora_B\n",
      "tensor(19.2006, device='cuda:0')\n",
      "all_modules.21.NIN_0.lora_A\n",
      "tensor(2.8326, device='cuda:0')\n",
      "all_modules.21.NIN_0.lora_B\n",
      "tensor(2.7953, device='cuda:0')\n",
      "all_modules.21.NIN_1.lora_A\n",
      "tensor(2.8699, device='cuda:0')\n",
      "all_modules.21.NIN_1.lora_B\n",
      "tensor(2.4379, device='cuda:0')\n",
      "all_modules.21.NIN_2.lora_A\n",
      "tensor(3.0240, device='cuda:0')\n",
      "all_modules.21.NIN_2.lora_B\n",
      "tensor(2.2425, device='cuda:0')\n",
      "all_modules.21.NIN_3.lora_A\n",
      "tensor(4.4761, device='cuda:0')\n",
      "all_modules.21.NIN_3.lora_B\n",
      "tensor(1.2459, device='cuda:0')\n",
      "all_modules.22.Conv_0.weight tensor(41.0699, device='cuda:0')\n",
      "all_modules.22.Conv_0.lora_A\n",
      "tensor(33.5774, device='cuda:0')\n",
      "all_modules.22.Conv_0.lora_B\n",
      "tensor(20.5832, device='cuda:0')\n",
      "all_modules.22.Conv_1.weight tensor(63.1153, device='cuda:0')\n",
      "all_modules.22.Conv_1.lora_A\n",
      "tensor(27.6894, device='cuda:0')\n",
      "all_modules.22.Conv_1.lora_B\n",
      "tensor(27.9832, device='cuda:0')\n",
      "all_modules.23.Conv_0.weight tensor(90.8489, device='cuda:0')\n",
      "all_modules.23.Conv_0.lora_A\n",
      "tensor(48.0791, device='cuda:0')\n",
      "all_modules.23.Conv_0.lora_B\n",
      "tensor(19.6216, device='cuda:0')\n",
      "all_modules.23.Conv_1.weight tensor(42.6400, device='cuda:0')\n",
      "all_modules.23.Conv_1.lora_A\n",
      "tensor(29.5551, device='cuda:0')\n",
      "all_modules.23.Conv_1.lora_B\n",
      "tensor(18.7822, device='cuda:0')\n",
      "all_modules.24.Conv_0.weight tensor(134.9875, device='cuda:0')\n",
      "all_modules.24.Conv_0.lora_A\n",
      "tensor(60.0916, device='cuda:0')\n",
      "all_modules.24.Conv_0.lora_B\n",
      "tensor(21.3050, device='cuda:0')\n",
      "all_modules.24.Conv_1.weight tensor(57.9306, device='cuda:0')\n",
      "all_modules.24.Conv_1.lora_A\n",
      "tensor(37.1379, device='cuda:0')\n",
      "all_modules.24.Conv_1.lora_B\n",
      "tensor(26.3208, device='cuda:0')\n",
      "all_modules.25.Conv_0.weight tensor(98.2031, device='cuda:0')\n",
      "all_modules.25.Conv_0.lora_A\n",
      "tensor(65.2895, device='cuda:0')\n",
      "all_modules.25.Conv_0.lora_B\n",
      "tensor(23.6822, device='cuda:0')\n",
      "all_modules.25.Conv_1.weight tensor(42.1343, device='cuda:0')\n",
      "all_modules.25.Conv_1.lora_A\n",
      "tensor(32.9669, device='cuda:0')\n",
      "all_modules.25.Conv_1.lora_B\n",
      "tensor(25.8096, device='cuda:0')\n",
      "all_modules.26.NIN_0.lora_A\n",
      "tensor(3.6911, device='cuda:0')\n",
      "all_modules.26.NIN_0.lora_B\n",
      "tensor(2.7440, device='cuda:0')\n",
      "all_modules.26.NIN_1.lora_A\n",
      "tensor(3.2928, device='cuda:0')\n",
      "all_modules.26.NIN_1.lora_B\n",
      "tensor(1.9867, device='cuda:0')\n",
      "all_modules.26.NIN_2.lora_A\n",
      "tensor(3.1623, device='cuda:0')\n",
      "all_modules.26.NIN_2.lora_B\n",
      "tensor(3.2181, device='cuda:0')\n",
      "all_modules.26.NIN_3.lora_A\n",
      "tensor(9.0917, device='cuda:0')\n",
      "all_modules.26.NIN_3.lora_B\n",
      "tensor(1.9803, device='cuda:0')\n",
      "all_modules.29.Conv_0.weight tensor(46.9249, device='cuda:0')\n",
      "all_modules.29.Conv_0.lora_A\n",
      "tensor(36.1751, device='cuda:0')\n",
      "all_modules.29.Conv_0.lora_B\n",
      "tensor(19.6572, device='cuda:0')\n",
      "all_modules.29.Conv_1.weight tensor(36.1739, device='cuda:0')\n",
      "all_modules.29.Conv_1.lora_A\n",
      "tensor(35.2991, device='cuda:0')\n",
      "all_modules.29.Conv_1.lora_B\n",
      "tensor(15.6021, device='cuda:0')\n",
      "all_modules.30.Conv_0.weight tensor(90.9452, device='cuda:0')\n",
      "all_modules.30.Conv_0.lora_A\n",
      "tensor(79.7153, device='cuda:0')\n",
      "all_modules.30.Conv_0.lora_B\n",
      "tensor(21.4784, device='cuda:0')\n",
      "all_modules.30.Conv_1.weight tensor(56.5789, device='cuda:0')\n",
      "all_modules.30.Conv_1.lora_A\n",
      "tensor(47.6684, device='cuda:0')\n",
      "all_modules.30.Conv_1.lora_B\n",
      "tensor(23.6184, device='cuda:0')\n",
      "all_modules.31.Conv_0.weight tensor(77.1727, device='cuda:0')\n",
      "all_modules.31.Conv_0.lora_A\n",
      "tensor(75.4640, device='cuda:0')\n",
      "all_modules.31.Conv_0.lora_B\n",
      "tensor(22.1553, device='cuda:0')\n",
      "all_modules.31.Conv_1.weight tensor(41.1161, device='cuda:0')\n",
      "all_modules.31.Conv_1.lora_A\n",
      "tensor(40.4100, device='cuda:0')\n",
      "all_modules.31.Conv_1.lora_B\n",
      "tensor(23.2832, device='cuda:0')\n",
      "all_modules.32.Conv_0.weight tensor(9.7694, device='cuda:0')\n",
      "all_modules.32.Conv_0.lora_A\n",
      "tensor(32.2586, device='cuda:0')\n",
      "all_modules.32.Conv_0.lora_B\n",
      "tensor(18.9417, device='cuda:0')\n",
      "all_modules.32.Conv_1.weight tensor(16.7751, device='cuda:0')\n",
      "all_modules.32.Conv_1.lora_A\n",
      "tensor(26.4981, device='cuda:0')\n",
      "all_modules.32.Conv_1.lora_B\n",
      "tensor(21.1090, device='cuda:0')\n",
      "all_modules.34.weight tensor(0.0071, device='cuda:0')\n",
      "all_modules.34.lora_A\n",
      "tensor(7.5997, device='cuda:0')\n",
      "all_modules.34.lora_B\n",
      "tensor(0.0028, device='cuda:0')\n",
      "all_modules.35.Conv_0.weight tensor(25.0504, device='cuda:0')\n",
      "all_modules.35.Conv_0.lora_A\n",
      "tensor(35.0956, device='cuda:0')\n",
      "all_modules.35.Conv_0.lora_B\n",
      "tensor(17.9877, device='cuda:0')\n",
      "all_modules.35.Conv_1.weight tensor(35.2175, device='cuda:0')\n",
      "all_modules.35.Conv_1.lora_A\n",
      "tensor(40.9634, device='cuda:0')\n",
      "all_modules.35.Conv_1.lora_B\n",
      "tensor(16.1014, device='cuda:0')\n",
      "all_modules.36.Conv_0.weight tensor(24.1203, device='cuda:0')\n",
      "all_modules.36.Conv_0.lora_A\n",
      "tensor(61.4481, device='cuda:0')\n",
      "all_modules.36.Conv_0.lora_B\n",
      "tensor(10.6698, device='cuda:0')\n",
      "all_modules.36.Conv_1.weight tensor(14.9214, device='cuda:0')\n",
      "all_modules.36.Conv_1.lora_A\n",
      "tensor(26.1947, device='cuda:0')\n",
      "all_modules.36.Conv_1.lora_B\n",
      "tensor(9.1760, device='cuda:0')\n",
      "all_modules.37.Conv_0.weight tensor(12.8444, device='cuda:0')\n",
      "all_modules.37.Conv_0.lora_A\n",
      "tensor(37.4257, device='cuda:0')\n",
      "all_modules.37.Conv_0.lora_B\n",
      "tensor(9.8913, device='cuda:0')\n",
      "all_modules.37.Conv_1.weight tensor(7.4001, device='cuda:0')\n",
      "all_modules.37.Conv_1.lora_A\n",
      "tensor(18.2998, device='cuda:0')\n",
      "all_modules.37.Conv_1.lora_B\n",
      "tensor(7.2782, device='cuda:0')\n",
      "all_modules.38.Conv_0.weight tensor(9.1200, device='cuda:0')\n",
      "all_modules.38.Conv_0.lora_A\n",
      "tensor(32.0985, device='cuda:0')\n",
      "all_modules.38.Conv_0.lora_B\n",
      "tensor(9.9762, device='cuda:0')\n",
      "all_modules.38.Conv_1.weight tensor(5.3861, device='cuda:0')\n",
      "all_modules.38.Conv_1.lora_A\n",
      "tensor(15.2700, device='cuda:0')\n",
      "all_modules.38.Conv_1.lora_B\n",
      "tensor(6.8865, device='cuda:0')\n",
      "all_modules.40.weight tensor(0.0009, device='cuda:0')\n",
      "all_modules.40.lora_A\n",
      "tensor(3.8799, device='cuda:0')\n",
      "all_modules.40.lora_B\n",
      "tensor(0.0010, device='cuda:0')\n",
      "all_modules.41.Conv_0.weight tensor(6.9354, device='cuda:0')\n",
      "all_modules.41.Conv_0.lora_A\n",
      "tensor(20.0206, device='cuda:0')\n",
      "all_modules.41.Conv_0.lora_B\n",
      "tensor(8.0525, device='cuda:0')\n",
      "all_modules.41.Conv_1.weight tensor(5.6240, device='cuda:0')\n",
      "all_modules.41.Conv_1.lora_A\n",
      "tensor(15.1513, device='cuda:0')\n",
      "all_modules.41.Conv_1.lora_B\n",
      "tensor(6.2865, device='cuda:0')\n",
      "all_modules.42.Conv_0.weight tensor(9.8718, device='cuda:0')\n",
      "all_modules.42.Conv_0.lora_A\n",
      "tensor(30.5132, device='cuda:0')\n",
      "all_modules.42.Conv_0.lora_B\n",
      "tensor(9.3717, device='cuda:0')\n",
      "all_modules.42.Conv_1.weight tensor(3.8392, device='cuda:0')\n",
      "all_modules.42.Conv_1.lora_A\n",
      "tensor(11.9714, device='cuda:0')\n",
      "all_modules.42.Conv_1.lora_B\n",
      "tensor(5.3028, device='cuda:0')\n",
      "all_modules.43.Conv_0.weight tensor(6.9457, device='cuda:0')\n",
      "all_modules.43.Conv_0.lora_A\n",
      "tensor(24.8898, device='cuda:0')\n",
      "all_modules.43.Conv_0.lora_B\n",
      "tensor(8.5607, device='cuda:0')\n",
      "all_modules.43.Conv_1.weight tensor(2.1860, device='cuda:0')\n",
      "all_modules.43.Conv_1.lora_A\n",
      "tensor(9.4451, device='cuda:0')\n",
      "all_modules.43.Conv_1.lora_B\n",
      "tensor(4.2949, device='cuda:0')\n",
      "all_modules.44.Conv_0.weight tensor(4.6851, device='cuda:0')\n",
      "all_modules.44.Conv_0.lora_A\n",
      "tensor(21.5250, device='cuda:0')\n",
      "all_modules.44.Conv_0.lora_B\n",
      "tensor(7.5402, device='cuda:0')\n",
      "all_modules.44.Conv_1.weight tensor(1.4265, device='cuda:0')\n",
      "all_modules.44.Conv_1.lora_A\n",
      "tensor(7.8791, device='cuda:0')\n",
      "all_modules.44.Conv_1.lora_B\n",
      "tensor(4.2458, device='cuda:0')\n",
      "all_modules.46.weight tensor(0.0016, device='cuda:0')\n",
      "all_modules.46.lora_A\n",
      "tensor(5.6213, device='cuda:0')\n",
      "all_modules.46.lora_B\n",
      "tensor(0.0057, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "load_state1 = torch.load(\"./data/checkpoints/generative_model/flowMatching/ncsnpp-afhq-31000-model\")\n",
    "load_state2 = torch.load(\"./data/checkpoints/generative_model/flowMatching/lora_ncsnpp-afhq-2000-model\")\n",
    "print(load_state2.keys() - load_state1.keys())\n",
    "for key in load_state2.keys():\n",
    "    if key in load_state1.keys():\n",
    "        diff = torch.sum((load_state1[key] - load_state2[key]) ** 2)\n",
    "        if diff > 1e-6:\n",
    "            print(key, diff)\n",
    "    else :\n",
    "        print(key)\n",
    "        print(torch.sum(load_state2[key]**2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
